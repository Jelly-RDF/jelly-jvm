package eu.neverblink.jelly.core

import com.google.protobuf.{ByteString, Descriptors}
import eu.neverblink.jelly.core.proto.v1.*
import org.scalatest.matchers.should.Matchers
import org.scalatest.wordspec.AnyWordSpec

import java.io.{ByteArrayInputStream, ByteArrayOutputStream}

/**
 * Tests for some auxiliary methods (e.g., Text Format serialization) of the generated Protobuf messages.
 *
 * This also tests the classes generated by Google's protoc-java, from the core-protos-google module.
 */
class ProtoAuxiliarySpec extends AnyWordSpec, Matchers:
  import ProtoTestCases.*

  val opt = JellyOptions.SMALL_GENERALIZED
  val testCasesRaw: Seq[(String, TestCase[?], Map[String, ByteString])] = Seq(
    ("Triples1", Triples1, Map.empty),
    ("Triples2NsDecl", Triples2NsDecl, Map("key" -> ByteString.copyFromUtf8("test"))),
    ("Quads1", Quads1, Map.empty),
    (
      "Quads2RepeatDefault",
      Quads2RepeatDefault,
      Map(
        "keyZeros" -> ByteString.copyFrom(Array.ofDim[Byte](10)),
        "keyOnes" -> ByteString.copyFrom(Array.fill[Byte](10)(1)),
      )),
    ("Graphs1", Graphs1, Map.empty),
  )
  val testCases = testCasesRaw
    .map((name, tc, metadata) => (
    name,
    tc.encodedFull(opt, 1000, metadata).head
  ))

  val descriptors: Array[(String, Descriptors.Descriptor)] = classOf[Rdf].getDeclaredFields
    .filter(_.getType == classOf[com.google.protobuf.Descriptors.Descriptor])
    .map(f => { f.setAccessible(true) ; f })
    .map(f => (
      f.getName,
      f.get(null).asInstanceOf[com.google.protobuf.Descriptors.Descriptor]
    ))

  for ((name, descriptor) <- descriptors) do
    s"message descriptor $name" should {
      "have the correct name" in {
        val expectedName = name.replace("_descriptor", "").split("_").last
        descriptor.getName should be(expectedName)
      }
    }

  "RdfStreamFrame" should {
    // TODO: restore functionality
//    "serialize to string with toProtoString" when {
//      for ((name, tc) <- testCases) do s"test case $name" in {
//        val str = tc.toProtoString
//        str should not be empty
//      }
//    }
//
//    "deserialize from string with fromAscii" when {
//      for ((name, tc) <- testCases) do s"test case $name" in {
//        val str = tc.toProtoString
//        val frame = RdfStreamFrame.fromAscii(str)
//        frame should be(tc)
//      }
//    }

    // This case is mostly here to test metadata serialization/deserialization
    // in a round-trip setting.
    "round-trip with non-delimited bytes" when {
      for ((name, tc) <- testCases) do s"test case $name" in {
        val bytes = tc.toByteArray
        val frame = RdfStreamFrame.parseFrom(bytes)
        frame should be (tc)
      }
    }

    "round-trip with delimited bytes" when {
      for ((name, tc) <- testCases) do s"test case $name" in {
        val os = new ByteArrayOutputStream()
        tc.writeDelimitedTo(os)
        val bytes = os.toByteArray
        val frame = RdfStreamFrame.parseDelimitedFrom(ByteArrayInputStream(bytes))
        frame should be (tc)
      }
    }

    val deeplyNestedFrame = {
      var triple = RdfTriple.newInstance()
      for (i <- 1 to 100) {
        triple = RdfTriple.newInstance()
          .setSTripleTerm(triple)
      }
      RdfStreamFrame.newInstance()
        .addRows(RdfStreamRow.newInstance().setTriple(triple))
    }

    "[SECURITY] reject parsing too deeply nested messages (non-delimited)" in {
      val bytes = deeplyNestedFrame.toByteArray
      val exception = intercept[RuntimeException] {
        RdfStreamFrame.parseFrom(bytes)
      }
      exception.getMessage should include("depth exceeded: 65")
    }

    "[SECURITY] reject parsing too deeply nested messages (delimited)" in {
      val os = new ByteArrayOutputStream()
      deeplyNestedFrame.writeDelimitedTo(os)
      val bytes = os.toByteArray
      val exception = intercept[RuntimeException] {
        RdfStreamFrame.parseDelimitedFrom(ByteArrayInputStream(bytes))
      }
      exception.getMessage should include("depth exceeded: 65")
    }
  }
